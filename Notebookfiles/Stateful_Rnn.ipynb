{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stateful Rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9DdHdug6BV3BtVCA0JzrA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9zDxHWwRMg3"
      },
      "source": [
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    !pip install -q -U transformers\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "\n",
        "#COPIED MODULE PART"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vXqNkpXXEqo"
      },
      "source": [
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(shakespeare_text)\n",
        "max_id = len(tokenizer.word_index) # 고유 글자 개수.\n",
        "dataset_size = tokenizer.document_count # 총 글자 개수."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0sFYwiNTM5e"
      },
      "source": [
        "#상태를 가지고, 모델이 마지막 상태를 다음 훈련 배치의 초기상태로 사용한다는\n",
        "#Stateful RNN\n",
        "#각 입력 시퀀스가 이전 배치 시퀀스 끝난 시점 시작.\n",
        "#순차적인 입력 시퀀스를 요함\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2uvoUw19Eyc"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2DbdfTsU0Aw"
      },
      "source": [
        "batch_size = 32 #길이가 동일한 32개 텍스트로 나누고 \n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:#각 나눠진 텍스트에 대해 아래의 작업을 반복한다.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)#각 파트의 데이터셋을 뽑아와 텐서로 변환.\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)#윈도우를 만들어 나눠둠\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))#다시 플랫-맵으로.\n",
        "    datasets.append(dataset) #datasets에 위 과정을 거친 배치가 차곡차곡 쌓인다.\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))#연속적인 배치가 만들어짐\n",
        "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn4BPpj5U16N"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,#이전 에폭의 상태를 기억...!\n",
        "                     dropout=0.2, #recurrent_dropout=0.2,\n",
        "                     batch_input_shape=[batch_size, None, max_id]),#상태가 있는 rnn은 배치 크기를 알아야한다(배치에 있는 입력 시퀀스의 상태를 보존해야 한다.)\n",
        "                     #따라서 batch_input_shape 매개변수 지정.\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2), #recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWrv1OwzXKNi"
      },
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()\n",
        "\n",
        "#매 에폭마다 상태를 재설정하는 콜백함수 제작.\n",
        "#모든 메소드를 알 수는 없다. \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgizc3HNXTHq",
        "outputId": "eac0e2df-bd33-42d7-a0d1-d9e21dc1df48"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "steps_per_epoch = train_size // batch_size // n_steps\n",
        "history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50,\n",
        "                    callbacks=[ResetStatesCallback()])\n",
        "#배치당 샘플이 하나(윈도우가 하나)기에 에폭을 늘렸다고 한다."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 37s 12ms/step - loss: 2.9056\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 2.2891\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 2.1380\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 2.0546\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.9976\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 1.9574\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.9249\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.9035\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8853\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8665\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8539\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8437\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8359\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.8280\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8169\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8089\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.8030\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7987\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7916\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7856\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7813\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7790\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7753\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7688\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7680\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7627\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7594\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7578\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7533\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7534\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7490\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7476\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7468\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7437\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7391\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7416\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7392\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7333\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7323\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7311\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7280\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7259\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7244\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7245\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7229\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7203\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7187\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7197\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7151\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.7146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrZ-p6-ZXckh"
      },
      "source": [
        "#이 모델을 훈련한 뒤 동일한 크기의 배치로만 예측을 만들 수 있기에, \n",
        "#이후 동일한 크기의 배치로만 예측이 만들어지기때문에, 이런 제약을 없애기 위해 동일한 구조의 \n",
        "#상태가 없는 모델을 만들고 상태가 있는 모델의 가중치를 복사한다.\n",
        "stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXtNWZYIYZFF"
      },
      "source": [
        "stateless_model.build(tf.TensorShape([None, None, max_id]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htfvy7smYgoT"
      },
      "source": [
        "\n",
        "stateless_model.set_weights(model.get_weights())#가중치를 위쪽 모델에서 가져오는 것.\n",
        "model = stateless_model\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58WR1K3oYoz-"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTC-mpBXYsHj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}